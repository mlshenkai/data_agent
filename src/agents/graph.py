import os
from dotenv import load_dotenv 
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent
from langchain_core.tools import tool
from pydantic import BaseModel, Field
import matplotlib
import json
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import pymysql
from langchain_tavily import TavilySearch
import os
import time
from datetime import datetime
 
# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(override=True)
 
# âœ… åˆ›å»ºTavilyæœç´¢å·¥å…·
search_tool = TavilySearch(max_results=5, topic="general")
 
# âœ… åˆ›å»ºSQLæŸ¥è¯¢å·¥å…·
description = """
å½“ç”¨æˆ·éœ€è¦è¿›è¡Œæ•°æ®åº“æŸ¥è¯¢å·¥ä½œæ—¶ï¼Œè¯·è°ƒç”¨è¯¥å‡½æ•°ã€‚
è¯¥å‡½æ•°ç”¨äºåœ¨æŒ‡å®šMySQLæœåŠ¡å™¨ä¸Šè¿è¡Œä¸€æ®µSQLä»£ç ï¼Œå®Œæˆæ•°æ®æŸ¥è¯¢ç›¸å…³å·¥ä½œï¼Œ
å¹¶ä¸”å½“å‰å‡½æ•°æ˜¯ä½¿ç”¨pymsqlè¿æ¥MySQLæ•°æ®åº“ã€‚
æœ¬å‡½æ•°åªè´Ÿè´£è¿è¡ŒSQLä»£ç å¹¶è¿›è¡Œæ•°æ®æŸ¥è¯¢ï¼Œè‹¥è¦è¿›è¡Œæ•°æ®æå–ï¼Œåˆ™ä½¿ç”¨å¦ä¸€ä¸ªextract_dataå‡½æ•°ã€‚
"""
 
# å®šä¹‰ç»“æ„åŒ–å‚æ•°æ¨¡å‹
class SQLQuerySchema(BaseModel):
    sql_query: str = Field(description=description)
 
# å°è£…ä¸º LangGraph å·¥å…·
@tool(args_schema=SQLQuerySchema)
def sql_inter(sql_query: str) -> str:
    """
    å½“ç”¨æˆ·éœ€è¦è¿›è¡Œæ•°æ®åº“æŸ¥è¯¢å·¥ä½œæ—¶ï¼Œè¯·è°ƒç”¨è¯¥å‡½æ•°ã€‚
    è¯¥å‡½æ•°ç”¨äºåœ¨æŒ‡å®šMySQLæœåŠ¡å™¨ä¸Šè¿è¡Œä¸€æ®µSQLä»£ç ï¼Œå®Œæˆæ•°æ®æŸ¥è¯¢ç›¸å…³å·¥ä½œï¼Œ
    å¹¶ä¸”å½“å‰å‡½æ•°æ˜¯ä½¿ç”¨pymsqlè¿æ¥MySQLæ•°æ®åº“ã€‚
    æœ¬å‡½æ•°åªè´Ÿè´£è¿è¡ŒSQLä»£ç å¹¶è¿›è¡Œæ•°æ®æŸ¥è¯¢ï¼Œè‹¥è¦è¿›è¡Œæ•°æ®æå–ï¼Œåˆ™ä½¿ç”¨å¦ä¸€ä¸ªextract_dataå‡½æ•°ã€‚
    :param sql_query: å­—ç¬¦ä¸²å½¢å¼çš„SQLæŸ¥ppadfsè¯¢è¯­å¥ï¼Œç”¨äºæ‰§è¡Œå¯¹MySQLä¸­telco_dbæ•°æ®åº“ä¸­å„å¼ è¡¨è¿›è¡ŒæŸ¥è¯¢ï¼Œå¹¶è·å¾—å„è¡¨ä¸­çš„å„ç±»ç›¸å…³ä¿¡æ¯
    :returnï¼šsql_queryåœ¨MySQLä¸­çš„è¿è¡Œç»“æœã€‚   
    """
    # print("æ­£åœ¨è°ƒç”¨ sql_inter å·¥å…·è¿è¡Œ SQL æŸ¥è¯¢...")
     
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv(override=True)
    host = os.getenv('HOST')
    user = os.getenv('USER')
    mysql_pw = os.getenv('MYSQL_PW')
    db = os.getenv('DB_NAME')
    port = os.getenv('PORT')
     
    # åˆ›å»ºè¿æ¥
    connection = pymysql.connect(
        host=host,
        user=user,
        passwd=mysql_pw,
        db=db,
        port=int(port),
        charset='utf8'
    )
     
    try:
        with connection.cursor() as cursor:
            cursor.execute(sql_query)
            results = cursor.fetchall()
            # print("SQL æŸ¥è¯¢å·²æˆåŠŸæ‰§è¡Œï¼Œæ­£åœ¨æ•´ç†ç»“æœ...")
    finally:
        connection.close()
 
    # å°†ç»“æœä»¥ JSON å­—ç¬¦ä¸²å½¢å¼è¿”å›
    return json.dumps(results, ensure_ascii=False)
 
# âœ… åˆ›å»ºæ•°æ®æå–å·¥å…·
# å®šä¹‰ç»“æ„åŒ–å‚æ•°
class ExtractQuerySchema(BaseModel):
    sql_query: str = Field(description="ç”¨äºä» MySQL æå–æ•°æ®çš„ SQL æŸ¥è¯¢è¯­å¥ã€‚")
    df_name: str = Field(description="æŒ‡å®šç”¨äºä¿å­˜ç»“æœçš„ pandas å˜é‡åç§°ï¼ˆå­—ç¬¦ä¸²å½¢å¼ï¼‰ã€‚")
 
# æ³¨å†Œä¸º Agent å·¥å…·
@tool(args_schema=ExtractQuerySchema)
def extract_data(sql_query: str, df_name: str) -> str:
    """
    ç”¨äºåœ¨MySQLæ•°æ®åº“ä¸­æå–ä¸€å¼ è¡¨åˆ°å½“å‰Pythonç¯å¢ƒä¸­ï¼Œæ³¨æ„ï¼Œæœ¬å‡½æ•°åªè´Ÿè´£æ•°æ®è¡¨çš„æå–ï¼Œ
    å¹¶ä¸è´Ÿè´£æ•°æ®æŸ¥è¯¢ï¼Œè‹¥éœ€è¦åœ¨MySQLä¸­è¿›è¡Œæ•°æ®æŸ¥è¯¢ï¼Œè¯·ä½¿ç”¨sql_interå‡½æ•°ã€‚
    åŒæ—¶éœ€è¦æ³¨æ„ï¼Œç¼–å†™å¤–éƒ¨å‡½æ•°çš„å‚æ•°æ¶ˆæ¯æ—¶ï¼Œå¿…é¡»æ˜¯æ»¡è¶³jsonæ ¼å¼çš„å­—ç¬¦ä¸²ï¼Œ
    :param sql_query: å­—ç¬¦ä¸²å½¢å¼çš„SQLæŸ¥è¯¢è¯­å¥ï¼Œç”¨äºæå–MySQLä¸­çš„æŸå¼ è¡¨ã€‚
    :param df_name: å°†MySQLæ•°æ®åº“ä¸­æå–çš„è¡¨æ ¼è¿›è¡Œæœ¬åœ°ä¿å­˜æ—¶çš„å˜é‡åï¼Œä»¥å­—ç¬¦ä¸²å½¢å¼è¡¨ç¤ºã€‚
    :returnï¼šè¡¨æ ¼è¯»å–å’Œä¿å­˜ç»“æœ
    """
    print("æ­£åœ¨è°ƒç”¨ extract_data å·¥å…·è¿è¡Œ SQL æŸ¥è¯¢...")
     
    load_dotenv(override=True)
    host = os.getenv('HOST')
    user = os.getenv('USER')
    mysql_pw = os.getenv('MYSQL_PW')
    db = os.getenv('DB_NAME')
    port = os.getenv('PORT')
 
    # åˆ›å»ºæ•°æ®åº“è¿æ¥
    connection = pymysql.connect(
        host=host,
        user=user,
        passwd=mysql_pw,
        db=db,
        port=int(port),
        charset='utf8'
    )
 
    try:
        # æ‰§è¡Œ SQL å¹¶ä¿å­˜ä¸ºå…¨å±€å˜é‡
        df = pd.read_sql(sql_query, connection)
        globals()[df_name] = df
        # print("æ•°æ®æˆåŠŸæå–å¹¶ä¿å­˜ä¸ºå…¨å±€å˜é‡ï¼š", df_name)
        return f"âœ… æˆåŠŸåˆ›å»º pandas å¯¹è±¡ `{df_name}`ï¼ŒåŒ…å«ä» MySQL æå–çš„æ•°æ®ã€‚"
    except Exception as e:
        return f"âŒ æ‰§è¡Œå¤±è´¥ï¼š{e}"
    finally:
        connection.close()
 
# âœ…åˆ›å»ºPythonä»£ç æ‰§è¡Œå·¥å…·
# Pythonä»£ç æ‰§è¡Œå·¥å…·ç»“æ„åŒ–å‚æ•°è¯´æ˜
class PythonCodeInput(BaseModel):
    py_code: str = Field(description="ä¸€æ®µåˆæ³•çš„ Python ä»£ç å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ '2 + 2' æˆ– 'x = 3\\ny = x * 2'")
 
@tool(args_schema=PythonCodeInput)
def python_inter(py_code):
    """
    å½“ç”¨æˆ·éœ€è¦ç¼–å†™Pythonç¨‹åºå¹¶æ‰§è¡Œæ—¶ï¼Œè¯·è°ƒç”¨è¯¥å‡½æ•°ã€‚
    è¯¥å‡½æ•°å¯ä»¥æ‰§è¡Œä¸€æ®µPythonä»£ç å¹¶è¿”å›æœ€ç»ˆç»“æœï¼Œéœ€è¦æ³¨æ„ï¼Œæœ¬å‡½æ•°åªèƒ½æ‰§è¡Œéç»˜å›¾ç±»çš„ä»£ç ï¼Œè‹¥æ˜¯ç»˜å›¾ç›¸å…³ä»£ç ï¼Œåˆ™éœ€è¦è°ƒç”¨fig_interå‡½æ•°è¿è¡Œã€‚
    """   
    g = globals()
    try:
        # å°è¯•å¦‚æœæ˜¯è¡¨è¾¾å¼ï¼Œåˆ™è¿”å›è¡¨è¾¾å¼è¿è¡Œç»“æœ
        return str(eval(py_code, g))
    # è‹¥æŠ¥é”™ï¼Œåˆ™å…ˆæµ‹è¯•æ˜¯å¦æ˜¯å¯¹ç›¸åŒå˜é‡é‡å¤èµ‹å€¼
    except Exception as e:
        global_vars_before = set(g.keys())
        try:            
            exec(py_code, g)
        except Exception as e:
            return f"ä»£ç æ‰§è¡Œæ—¶æŠ¥é”™{e}"
        global_vars_after = set(g.keys())
        new_vars = global_vars_after - global_vars_before
        # è‹¥å­˜åœ¨æ–°å˜é‡
        if new_vars:
            result = {var: g[var] for var in new_vars}
            # print("ä»£ç å·²é¡ºåˆ©æ‰§è¡Œï¼Œæ­£åœ¨è¿›è¡Œç»“æœæ¢³ç†...")
            return str(result)
        else:
            # print("ä»£ç å·²é¡ºåˆ©æ‰§è¡Œï¼Œæ­£åœ¨è¿›è¡Œç»“æœæ¢³ç†...")
            return "å·²ç»é¡ºåˆ©æ‰§è¡Œä»£ç "
 
# âœ… åˆ›å»ºç»˜å›¾å·¥å…·
# ç»˜å›¾å·¥å…·ç»“æ„åŒ–å‚æ•°è¯´æ˜
class FigCodeInput(BaseModel):
    py_code: str = Field(description="è¦æ‰§è¡Œçš„ Python ç»˜å›¾ä»£ç ï¼Œå¿…é¡»ä½¿ç”¨ matplotlib/seaborn åˆ›å»ºå›¾åƒå¹¶èµ‹å€¼ç»™å˜é‡")
    fname: str = Field(description="å›¾åƒå¯¹è±¡çš„å˜é‡åï¼Œä¾‹å¦‚ 'fig'ï¼Œç”¨äºä»ä»£ç ä¸­æå–å¹¶ä¿å­˜ä¸ºå›¾ç‰‡")
 
@tool(args_schema=FigCodeInput)
def fig_inter(py_code: str, fname: str) -> str:
    """
    å½“ç”¨æˆ·éœ€è¦ä½¿ç”¨ Python è¿›è¡Œå¯è§†åŒ–ç»˜å›¾ä»»åŠ¡æ—¶ï¼Œè¯·è°ƒç”¨è¯¥å‡½æ•°ã€‚
 
    æ³¨æ„ï¼š
    1. æ‰€æœ‰ç»˜å›¾ä»£ç å¿…é¡»åˆ›å»ºä¸€ä¸ªå›¾åƒå¯¹è±¡ï¼Œå¹¶å°†å…¶èµ‹å€¼ä¸ºæŒ‡å®šå˜é‡åï¼ˆä¾‹å¦‚ `fig`ï¼‰ã€‚
    2. å¿…é¡»ä½¿ç”¨ `fig = plt.figure()` æˆ– `fig = plt.subplots()`ã€‚
    3. ä¸è¦ä½¿ç”¨ `plt.show()`ã€‚
    4. è¯·ç¡®ä¿ä»£ç æœ€åè°ƒç”¨ `fig.tight_layout()`ã€‚
    5. æ‰€æœ‰ç»˜å›¾ä»£ç ä¸­ï¼Œåæ ‡è½´æ ‡ç­¾ï¼ˆxlabelã€ylabelï¼‰ã€æ ‡é¢˜ï¼ˆtitleï¼‰ã€å›¾ä¾‹ï¼ˆlegendï¼‰ç­‰æ–‡æœ¬å†…å®¹ï¼Œå¿…é¡»ä½¿ç”¨è‹±æ–‡æè¿°ã€‚
 
    ç¤ºä¾‹ä»£ç ï¼š
    fig = plt.figure(figsize=(10,6))
    plt.plot([1,2,3], [4,5,6])
    fig.tight_layout()
    """
    # print("æ­£åœ¨è°ƒç”¨fig_interå·¥å…·è¿è¡ŒPythonä»£ç ...")
 
    # ä¿å­˜å½“å‰matplotlibåç«¯
    current_backend = matplotlib.get_backend()
    
    # åœ¨macOSä¸Šå¼ºåˆ¶ä½¿ç”¨Aggåç«¯ï¼Œé¿å…çº¿ç¨‹é—®é¢˜
    import platform
    if platform.system() == 'Darwin':  # macOS
        matplotlib.use('Agg')
    else:
        matplotlib.use('Agg')  # å…¶ä»–ç³»ç»Ÿä¹Ÿä½¿ç”¨Aggåç«¯
 
    local_vars = {"plt": plt, "pd": pd, "sns": sns}
     
    # åŠ¨æ€è®¾ç½®å›¾ç‰‡ä¿å­˜è·¯å¾„ï¼ˆæ”¯æŒä¸åŒæ“ä½œç³»ç»Ÿï¼‰
    current_dir = os.getcwd()
    
    # å°è¯•å¤šä¸ªå¯èƒ½çš„å›¾ç‰‡ä¿å­˜è·¯å¾„
    possible_paths = [
        os.path.join(current_dir, "frontend", "public", "images"),
        os.path.join(current_dir, "public", "images"),
        os.path.join(current_dir, "images"),
        os.path.join(current_dir, "static", "images")
    ]
    
    images_dir = None
    for path in possible_paths:
        try:
            if os.path.exists(path) or os.access(os.path.dirname(path), os.W_OK):
                images_dir = path
                break
        except:
            continue
    
    # å¦‚æœæ‰¾ä¸åˆ°åˆé€‚çš„è·¯å¾„ï¼Œä½¿ç”¨å½“å‰ç›®å½•ä¸‹çš„imagesæ–‡ä»¶å¤¹
    if images_dir is None:
        images_dir = os.path.join(current_dir, "images")
    
    # åˆ›å»ºå›¾ç‰‡ç›®å½•
    try:
        os.makedirs(images_dir, exist_ok=True)
    except Exception as e:
        return f"âŒ æ— æ³•åˆ›å»ºå›¾ç‰‡ç›®å½• {images_dir}ï¼š{str(e)}"
    
    try:
        g = globals()
        exec(py_code, g, local_vars)
        g.update(local_vars)
 
        fig = local_vars.get(fname, None)
        if fig:
            # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            image_filename = f"{fname}_{timestamp}.png"
            abs_path = os.path.join(images_dir, image_filename)  # âœ… ç»å¯¹è·¯å¾„
            rel_path = os.path.join("images", image_filename)    # âœ… è¿”å›ç›¸å¯¹è·¯å¾„ï¼ˆç»™å‰ç«¯ç”¨ï¼‰
 
            fig.savefig(abs_path, bbox_inches='tight')
            return f"âœ… å›¾ç‰‡å·²ä¿å­˜ï¼Œè·¯å¾„ä¸º: {rel_path}"
        else:
            return "âš ï¸ å›¾åƒå¯¹è±¡æœªæ‰¾åˆ°ï¼Œè¯·ç¡®è®¤å˜é‡åæ­£ç¡®å¹¶ä¸º matplotlib å›¾å¯¹è±¡ã€‚"
    except Exception as e:
        return f"âŒ æ‰§è¡Œå¤±è´¥ï¼š{e}"
    finally:
        plt.close('all')
        matplotlib.use(current_backend)
 
# âœ… åˆ›å»ºæ–‡ä»¶è¯»å–å·¥å…·
# æ–‡ä»¶è¯»å–å·¥å…·ç»“æ„åŒ–å‚æ•°è¯´æ˜
class ReadFileSchema(BaseModel):
    file_path: str = Field(description="æ–‡ä»¶è·¯å¾„ï¼Œæ”¯æŒç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„")
    file_type: str = Field(description="æ–‡ä»¶ç±»å‹ï¼ˆå¯é€‰ï¼Œè‡ªåŠ¨æ£€æµ‹ï¼‰", default="auto")
    read_params: dict = Field(description="è¯»å–å‚æ•°ï¼ˆå¯é€‰ï¼‰", default={})
    df_name: str = Field(description="ä¿å­˜çš„å˜é‡åï¼Œç”¨äºåç»­åˆ†æ")
    preview_lines: int = Field(description="é¢„è§ˆè¡Œæ•°ï¼ˆå¯é€‰ï¼Œ0è¡¨ç¤ºä¸é¢„è§ˆï¼‰", default=5)
    get_file_info: bool = Field(description="æ˜¯å¦è·å–æ–‡ä»¶ä¿¡æ¯", default=True)

@tool(args_schema=ReadFileSchema)
def read_file(file_path: str, file_type: str = "auto", read_params: dict = {}, 
              df_name: str = "", preview_lines: int = 5, get_file_info: bool = True) -> str:
    """
    å½“ç”¨æˆ·éœ€è¦è¯»å–æœ¬åœ°æ–‡ä»¶æ—¶ï¼Œè¯·è°ƒç”¨è¯¥å‡½æ•°ã€‚
    è¯¥å‡½æ•°æ”¯æŒå¤šç§æ–‡ä»¶æ ¼å¼çš„è¯»å–ï¼ŒåŒ…æ‹¬CSVã€Excelã€JSONã€Parquetã€æ–‡æœ¬æ–‡ä»¶ã€XMLã€HTMLã€SQLã€Pickleç­‰ã€‚
    
    æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼š
    - CSVæ–‡ä»¶ (.csv)
    - Excelæ–‡ä»¶ (.xlsx, .xls)
    - JSONæ–‡ä»¶ (.json)
    - Parquetæ–‡ä»¶ (.parquet)
    - æ–‡æœ¬æ–‡ä»¶ (.txt)
    - XMLæ–‡ä»¶ (.xml)
    - HTMLæ–‡ä»¶ (.html, .htm)
    - SQLæ–‡ä»¶ (.sql)
    - Pickleæ–‡ä»¶ (.pkl, .pickle)
    - å…¶ä»–pandasæ”¯æŒçš„æ ¼å¼
    
    æ–°å¢åŠŸèƒ½ï¼š
    1. æ–‡ä»¶é¢„è§ˆï¼šæ˜¾ç¤ºå‰Nè¡Œæ•°æ®
    2. æ–‡ä»¶ä¿¡æ¯ï¼šæ˜¾ç¤ºæ–‡ä»¶å¤§å°ã€ä¿®æ”¹æ—¶é—´ã€ç¼–ç ç­‰ä¿¡æ¯
    3. æ›´å¤šæ ¼å¼æ”¯æŒï¼šXMLã€HTMLã€SQLã€Pickle
    4. å¢å¼ºé”™è¯¯å¤„ç†ï¼šæä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
    5. ç¼–ç è‡ªåŠ¨æ£€æµ‹ï¼šè‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç¼–ç 
    
    æ³¨æ„ï¼š
    1. æ–‡ä»¶è·¯å¾„å¯ä»¥æ˜¯ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„
    2. å¦‚æœä¸æŒ‡å®šfile_typeï¼Œå°†æ ¹æ®æ–‡ä»¶æ‰©å±•åè‡ªåŠ¨æ£€æµ‹
    3. read_paramså¯ä»¥åŒ…å«pandasè¯»å–å‡½æ•°çš„é¢å¤–å‚æ•°
    4. è¯»å–çš„æ•°æ®å°†ä¿å­˜ä¸ºå…¨å±€å˜é‡ï¼Œå˜é‡åä¸ºdf_name
    5. preview_linesè®¾ç½®é¢„è§ˆè¡Œæ•°ï¼Œ0è¡¨ç¤ºä¸é¢„è§ˆ
    6. get_file_infoæ§åˆ¶æ˜¯å¦æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
    
    ç¤ºä¾‹ï¼š
    - è¯»å–CSVæ–‡ä»¶ï¼šfile_path="data.csv", df_name="df", preview_lines=10
    - è¯»å–Excelæ–‡ä»¶ï¼šfile_path="data.xlsx", df_name="excel_data", get_file_info=True
    - è¯»å–JSONæ–‡ä»¶ï¼šfile_path="data.json", df_name="json_data"
    - è¯»å–XMLæ–‡ä»¶ï¼šfile_path="data.xml", df_name="xml_data"
    """
    
    try:
        # å¤„ç†å‰ç«¯ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„
        if file_path.startswith("uploads/"):
            # å‰ç«¯ä¸Šä¼ çš„æ–‡ä»¶åœ¨frontend/public/uploads/ç›®å½•ä¸‹
            current_dir = os.getcwd()
            # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„
            possible_paths = [
                os.path.join(current_dir, "frontend", "public", file_path),
                os.path.join(current_dir, "public", file_path),
                os.path.join(current_dir, file_path),
            ]
            
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå­˜åœ¨çš„æ–‡ä»¶è·¯å¾„
            actual_file_path = None
            for path in possible_paths:
                if os.path.exists(path):
                    actual_file_path = path
                    break
            
            if actual_file_path is None:
                return f"âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼š{file_path}ã€‚å°è¯•çš„è·¯å¾„ï¼š{', '.join(possible_paths)}"
            
            file_path = actual_file_path
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(file_path):
            return f"âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼š{file_path}"
        
        # è·å–æ–‡ä»¶ä¿¡æ¯
        file_info = ""
        if get_file_info:
            try:
                stat = os.stat(file_path)
                file_size = stat.st_size
                modified_time = datetime.fromtimestamp(stat.st_mtime).strftime('%Y-%m-%d %H:%M:%S')
                
                # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
                if file_size < 1024:
                    size_str = f"{file_size} B"
                elif file_size < 1024 * 1024:
                    size_str = f"{file_size / 1024:.1f} KB"
                elif file_size < 1024 * 1024 * 1024:
                    size_str = f"{file_size / (1024 * 1024):.1f} MB"
                else:
                    size_str = f"{file_size / (1024 * 1024 * 1024):.1f} GB"
                
                file_info = f"ğŸ“ æ–‡ä»¶ä¿¡æ¯ï¼š\n- å¤§å°ï¼š{size_str}\n- ä¿®æ”¹æ—¶é—´ï¼š{modified_time}\n"
                
                # å°è¯•æ£€æµ‹ç¼–ç ï¼ˆä»…å¯¹æ–‡æœ¬æ–‡ä»¶ï¼‰
                file_extension = os.path.splitext(file_path)[1].lower()
                text_extensions = ['.csv', '.txt', '.json', '.xml', '.html', '.htm', '.sql']
                if file_extension in text_extensions:
                    try:
                        import chardet
                        with open(file_path, 'rb') as f:
                            raw_data = f.read(10000)  # è¯»å–å‰10KBè¿›è¡Œç¼–ç æ£€æµ‹
                            encoding_result = chardet.detect(raw_data)
                            if encoding_result['encoding']:
                                file_info += f"- ç¼–ç ï¼š{encoding_result['encoding']} (ç½®ä¿¡åº¦: {encoding_result['confidence']:.2f})\n"
                    except ImportError:
                        file_info += "- ç¼–ç ï¼šæœªæ£€æµ‹ï¼ˆéœ€è¦å®‰è£…chardetåº“ï¼‰\n"
                    except Exception:
                        file_info += "- ç¼–ç ï¼šæ£€æµ‹å¤±è´¥\n"
                
            except Exception as e:
                file_info = f"âš ï¸ æ— æ³•è·å–æ–‡ä»¶ä¿¡æ¯ï¼š{str(e)}\n"
        
        # è·å–æ–‡ä»¶æ‰©å±•å
        file_extension = os.path.splitext(file_path)[1].lower()
        
        # å¦‚æœæœªæŒ‡å®šæ–‡ä»¶ç±»å‹ï¼Œæ ¹æ®æ‰©å±•åè‡ªåŠ¨æ£€æµ‹
        if file_type == "auto":
            if file_extension == ".csv":
                file_type = "csv"
            elif file_extension in [".xlsx", ".xls"]:
                file_type = "excel"
            elif file_extension == ".json":
                file_type = "json"
            elif file_extension == ".parquet":
                file_type = "parquet"
            elif file_extension == ".txt":
                file_type = "text"
            elif file_extension == ".xml":
                file_type = "xml"
            elif file_extension in [".html", ".htm"]:
                file_type = "html"
            elif file_extension == ".sql":
                file_type = "sql"
            elif file_extension in [".pkl", ".pickle"]:
                file_type = "pickle"
            else:
                return f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼š{file_extension}ã€‚æ”¯æŒçš„æ ¼å¼ï¼šCSV, Excel, JSON, Parquet, TXT, XML, HTML, SQL, Pickle"
        
        # æ ¹æ®æ–‡ä»¶ç±»å‹è¯»å–æ•°æ®
        df = None
        read_method = ""
        
        if file_type == "csv":
            df = pd.read_csv(file_path, **read_params)
            read_method = "pd.read_csv()"
        elif file_type == "excel":
            df = pd.read_excel(file_path, **read_params)
            read_method = "pd.read_excel()"
        elif file_type == "json":
            df = pd.read_json(file_path, **read_params)
            read_method = "pd.read_json()"
        elif file_type == "parquet":
            df = pd.read_parquet(file_path, **read_params)
            read_method = "pd.read_parquet()"
        elif file_type == "text":
            df = pd.read_table(file_path, **read_params)
            read_method = "pd.read_table()"
        elif file_type == "xml":
            try:
                df = pd.read_xml(file_path, **read_params)
                read_method = "pd.read_xml()"
            except ImportError:
                return f"âŒ è¯»å–XMLæ–‡ä»¶éœ€è¦å®‰è£…lxmlåº“ã€‚è¯·è¿è¡Œï¼špip install lxml"
            except Exception as e:
                return f"âŒ XMLæ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}ã€‚è¯·æ£€æŸ¥XMLæ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚"
        elif file_type == "html":
            try:
                tables = pd.read_html(file_path, **read_params)
                if len(tables) == 0:
                    return f"âŒ HTMLæ–‡ä»¶ä¸­æœªæ‰¾åˆ°è¡¨æ ¼æ•°æ®"
                elif len(tables) == 1:
                    df = tables[0]
                else:
                    df = tables[0]  # é»˜è®¤å–ç¬¬ä¸€ä¸ªè¡¨æ ¼
                    file_info += f"âš ï¸ HTMLæ–‡ä»¶åŒ…å«{len(tables)}ä¸ªè¡¨æ ¼ï¼Œå·²åŠ è½½ç¬¬ä¸€ä¸ªè¡¨æ ¼\n"
                read_method = "pd.read_html()"
            except ImportError:
                return f"âŒ è¯»å–HTMLæ–‡ä»¶éœ€è¦å®‰è£…lxmlå’Œbeautifulsoup4åº“ã€‚è¯·è¿è¡Œï¼špip install lxml beautifulsoup4"
            except Exception as e:
                return f"âŒ HTMLæ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}ã€‚è¯·æ£€æŸ¥HTMLæ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚"
        elif file_type == "sql":
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    sql_content = f.read()
                # SQLæ–‡ä»¶é€šå¸¸åŒ…å«æŸ¥è¯¢è¯­å¥ï¼Œè¿™é‡Œè¿”å›SQLå†…å®¹è€Œä¸æ˜¯æ‰§è¡Œ
                return f"âœ… æˆåŠŸè¯»å–SQLæ–‡ä»¶ `{file_path}`\n{file_info}ğŸ“ SQLå†…å®¹ï¼š\n```sql\n{sql_content[:1000]}{'...' if len(sql_content) > 1000 else ''}\n```\nğŸ’¡ æç¤ºï¼šSQLæ–‡ä»¶å·²è¯»å–ï¼Œè¯·ä½¿ç”¨sql_interå·¥å…·æ‰§è¡Œå…¶ä¸­çš„æŸ¥è¯¢è¯­å¥ã€‚"
            except Exception as e:
                return f"âŒ SQLæ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}"
        elif file_type == "pickle":
            try:
                df = pd.read_pickle(file_path)
                read_method = "pd.read_pickle()"
            except Exception as e:
                return f"âŒ Pickleæ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}ã€‚è¯·ç¡®è®¤æ–‡ä»¶æ ¼å¼æ­£ç¡®ã€‚"
        else:
            return f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼š{file_type}ã€‚æ”¯æŒçš„ç±»å‹ï¼šcsv, excel, json, parquet, text, xml, html, sql, pickle"
        
        # å¦‚æœæ˜¯SQLæ–‡ä»¶ï¼Œå·²ç»åœ¨ä¸Šé¢å¤„ç†å¹¶è¿”å›
        if file_type == "sql":
            return  # è¿™è¡Œä¸ä¼šæ‰§è¡Œï¼Œä½†ä¿æŒä»£ç æ¸…æ™°
        
        # æ£€æŸ¥è¯»å–ç»“æœ
        if df is None:
            return f"âŒ æ•°æ®è¯»å–å¤±è´¥ï¼Œè¿”å›ç©ºå€¼"
        
        # æ„å»ºç»“æœæ¶ˆæ¯
        result_msg = f"âœ… æˆåŠŸè¯»å–æ–‡ä»¶ `{file_path}`ï¼ˆä½¿ç”¨{read_method}ï¼‰\n"
        result_msg += file_info
        result_msg += f"ğŸ“Š æ•°æ®æ¦‚è§ˆï¼š\n- å½¢çŠ¶ï¼š{df.shape}ï¼ˆ{df.shape[0]}è¡Œï¼Œ{df.shape[1]}åˆ—ï¼‰\n"
        result_msg += f"- åˆ—åï¼š{list(df.columns)}\n"
        
        # æ•°æ®ç±»å‹ä¿¡æ¯
        if hasattr(df, 'dtypes'):
            dtype_info = df.dtypes.value_counts()
            result_msg += f"- æ•°æ®ç±»å‹ï¼š{dict(dtype_info)}\n"
        
        # æ–‡ä»¶é¢„è§ˆ
        if preview_lines > 0:
            try:
                preview_df = df.head(preview_lines)
                result_msg += f"\nğŸ” æ•°æ®é¢„è§ˆï¼ˆå‰{preview_lines}è¡Œï¼‰ï¼š\n"
                result_msg += preview_df.to_string(max_cols=10, max_colwidth=20)
                
                if df.shape[0] > preview_lines:
                    result_msg += f"\n... ï¼ˆè¿˜æœ‰{df.shape[0] - preview_lines}è¡Œæ•°æ®ï¼‰"
            except Exception as e:
                result_msg += f"\nâš ï¸ æ•°æ®é¢„è§ˆå¤±è´¥ï¼š{str(e)}"
        
        # ä¿å­˜ä¸ºå…¨å±€å˜é‡
        if df_name:
            globals()[df_name] = df
            result_msg += f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜ä¸ºå˜é‡ `{df_name}`ï¼Œå¯ç”¨äºåç»­åˆ†æã€‚"
        else:
            result_msg += f"\nğŸ’¡ æç¤ºï¼šæœªæŒ‡å®šå˜é‡åï¼Œæ•°æ®æœªä¿å­˜ã€‚å¦‚éœ€ä¿å­˜è¯·æŒ‡å®šdf_nameå‚æ•°ã€‚"
            
        return result_msg
            
    except FileNotFoundError:
        return f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°ï¼š{file_path}ã€‚è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚"
    except PermissionError:
        return f"âŒ æ²¡æœ‰æƒé™è®¿é—®æ–‡ä»¶ï¼š{file_path}ã€‚è¯·æ£€æŸ¥æ–‡ä»¶æƒé™ã€‚"
    except pd.errors.EmptyDataError:
        return f"âŒ æ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®ï¼š{file_path}"
    except pd.errors.ParserError as e:
        return f"âŒ æ–‡ä»¶è§£æé”™è¯¯ï¼š{str(e)}ã€‚è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚"
    except UnicodeDecodeError as e:
        return f"âŒ æ–‡ä»¶ç¼–ç é”™è¯¯ï¼š{str(e)}ã€‚è¯·å°è¯•æŒ‡å®šæ­£ç¡®çš„ç¼–ç å‚æ•°ï¼Œå¦‚ï¼šread_params={{'encoding': 'gbk'}}"
    except Exception as e:
        return f"âŒ è¯»å–æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼š{str(e)}ã€‚è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼å’Œå†…å®¹æ˜¯å¦æ­£ç¡®ã€‚"
 
# âœ… åˆ›å»ºä¼˜åŒ–å›¾ç‰‡ç”Ÿæˆå·¥å…·
# ä¼˜åŒ–å›¾ç‰‡ç”Ÿæˆå·¥å…·ç»“æ„åŒ–å‚æ•°è¯´æ˜
class OptimizedFigCodeInput(BaseModel):
    py_code: str = Field(description="è¦æ‰§è¡Œçš„ Python ç»˜å›¾ä»£ç ï¼Œå¿…é¡»ä½¿ç”¨ matplotlib/seaborn åˆ›å»ºå›¾åƒå¹¶èµ‹å€¼ç»™å˜é‡")
    fname: str = Field(description="å›¾åƒå¯¹è±¡çš„å˜é‡åï¼Œä¾‹å¦‚ 'fig'ï¼Œç”¨äºä»ä»£ç ä¸­æå–å¹¶ä¿å­˜ä¸ºå›¾ç‰‡")
    format: str = Field(description="è¾“å‡ºæ ¼å¼ï¼ˆpng, jpg, jpeg, svg, pdf, webpï¼‰", default="png")
    dpi: int = Field(description="å›¾ç‰‡åˆ†è¾¨ç‡", default=300)
    quality: int = Field(description="å›¾ç‰‡è´¨é‡ï¼ˆJPG/WebPæ ¼å¼ï¼Œ1-100ï¼‰", default=95)
    optimize: bool = Field(description="æ˜¯å¦ä¼˜åŒ–å›¾ç‰‡", default=True)
    figsize: str = Field(description="å›¾ç‰‡å°ºå¯¸ï¼Œæ ¼å¼ä¸º'width,height'ï¼Œä¾‹å¦‚'10,6'", default=None)
    auto_resize: bool = Field(description="æ˜¯å¦è‡ªåŠ¨è°ƒæ•´å›¾ç‰‡å°ºå¯¸ä»¥é€‚åº”å†…å®¹", default=False)
    webp_quality: int = Field(description="WebPæ ¼å¼ä¸“ç”¨è´¨é‡å‚æ•°ï¼ˆ1-100ï¼Œä»…WebPæ ¼å¼ä½¿ç”¨ï¼‰", default=85)
    compression_level: int = Field(description="PNGå‹ç¼©çº§åˆ«ï¼ˆ0-9ï¼Œ0æ— å‹ç¼©ï¼Œ9æœ€å¤§å‹ç¼©ï¼‰", default=6)
    add_metadata: bool = Field(description="æ˜¯å¦æ·»åŠ å›¾ç‰‡å…ƒæ•°æ®", default=True)

@tool(args_schema=OptimizedFigCodeInput)
def optimized_fig_inter(py_code: str, fname: str, format: str = "png", dpi: int = 300, 
                       quality: int = 95, optimize: bool = True, figsize: str = None,
                       auto_resize: bool = False, webp_quality: int = 85, 
                       compression_level: int = 6, add_metadata: bool = True) -> str:
    """
    å½“ç”¨æˆ·éœ€è¦è¿›è¡Œé«˜è´¨é‡å›¾ç‰‡ç”Ÿæˆå’Œä¼˜åŒ–æ—¶ï¼Œè¯·è°ƒç”¨è¯¥å‡½æ•°ã€‚
    è¿™æ˜¯fig_interå·¥å…·çš„å¢å¼ºç‰ˆæœ¬ï¼Œæä¾›æ›´å¤šå›¾ç‰‡è´¨é‡æ§åˆ¶é€‰é¡¹å’Œæ ¼å¼æ”¯æŒã€‚
    
    åŠŸèƒ½ç‰¹æ€§ï¼š
    - æ”¯æŒå¤šç§å›¾ç‰‡æ ¼å¼ï¼ˆPNGã€JPGã€JPEGã€SVGã€PDFã€WebPï¼‰
    - å›¾ç‰‡è´¨é‡æ§åˆ¶ï¼ˆDPIã€å‹ç¼©ç‡ã€è´¨é‡å‚æ•°ï¼‰
    - é«˜çº§å‹ç¼©ä¼˜åŒ–ï¼ˆæ”¯æŒWebPæ ¼å¼çš„é«˜æ•ˆå‹ç¼©ï¼‰
    - åŠ¨æ€è·¯å¾„å¤„ç†ï¼ˆæ”¯æŒä¸åŒæ“ä½œç³»ç»Ÿï¼‰
    - è‡ªå®šä¹‰å›¾ç‰‡å°ºå¯¸å’Œè‡ªåŠ¨è°ƒæ•´
    - å›¾ç‰‡å…ƒæ•°æ®è®¾ç½®
    - å¢å¼ºé”™è¯¯å¤„ç†å’Œè¯Šæ–­ä¿¡æ¯
    
    æ–°å¢åŠŸèƒ½ï¼š
    1. WebPæ ¼å¼æ”¯æŒï¼šæä¾›æ›´å¥½çš„å‹ç¼©æ¯”å’Œè´¨é‡
    2. è‡ªåŠ¨å°ºå¯¸è°ƒæ•´ï¼šæ ¹æ®å†…å®¹è‡ªåŠ¨ä¼˜åŒ–å›¾ç‰‡å°ºå¯¸
    3. å¢å¼ºå‹ç¼©ç®—æ³•ï¼šé’ˆå¯¹ä¸åŒæ ¼å¼çš„ä¼˜åŒ–ç­–ç•¥
    4. å›¾ç‰‡å…ƒæ•°æ®ï¼šæ·»åŠ åˆ›å»ºæ—¶é—´ã€å·¥å…·ä¿¡æ¯ç­‰å…ƒæ•°æ®
    5. è¯¦ç»†é”™è¯¯è¯Šæ–­ï¼šæä¾›æ›´å‡†ç¡®çš„é”™è¯¯ä¿¡æ¯å’Œå»ºè®®
    
    æ³¨æ„ï¼š
    1. æ‰€æœ‰ç»˜å›¾ä»£ç å¿…é¡»åˆ›å»ºä¸€ä¸ªå›¾åƒå¯¹è±¡ï¼Œå¹¶å°†å…¶èµ‹å€¼ä¸ºæŒ‡å®šå˜é‡åï¼ˆä¾‹å¦‚ `fig`ï¼‰ã€‚
    2. å¿…é¡»ä½¿ç”¨ `fig = plt.figure()` æˆ– `fig = plt.subplots()`ã€‚
    3. ä¸è¦ä½¿ç”¨ `plt.show()`ã€‚
    4. è¯·ç¡®ä¿ä»£ç æœ€åè°ƒç”¨ `fig.tight_layout()`ã€‚
    5. æ‰€æœ‰ç»˜å›¾ä»£ç ä¸­ï¼Œåæ ‡è½´æ ‡ç­¾ï¼ˆxlabelã€ylabelï¼‰ã€æ ‡é¢˜ï¼ˆtitleï¼‰ã€å›¾ä¾‹ï¼ˆlegendï¼‰ç­‰æ–‡æœ¬å†…å®¹ï¼Œå¿…é¡»ä½¿ç”¨è‹±æ–‡æè¿°ã€‚
    
    å‚æ•°è¯´æ˜ï¼š
    - format: è¾“å‡ºæ ¼å¼ï¼Œæ”¯æŒ png, jpg, jpeg, svg, pdf, webp
    - dpi: å›¾ç‰‡åˆ†è¾¨ç‡ï¼Œé»˜è®¤300
    - quality: JPG/WebPæ ¼å¼çš„å›¾ç‰‡è´¨é‡ï¼Œ1-100ï¼Œé»˜è®¤95
    - optimize: æ˜¯å¦ä¼˜åŒ–å›¾ç‰‡ï¼Œé»˜è®¤True
    - figsize: å›¾ç‰‡å°ºå¯¸ï¼Œæ ¼å¼ä¸º'width,height'ï¼Œä¾‹å¦‚'10,6'
    - auto_resize: æ˜¯å¦è‡ªåŠ¨è°ƒæ•´å›¾ç‰‡å°ºå¯¸ä»¥é€‚åº”å†…å®¹
    - webp_quality: WebPä¸“ç”¨è´¨é‡å‚æ•°ï¼Œé€šå¸¸æ¯”JPGè´¨é‡å‚æ•°ä½10-15
    - compression_level: PNGå‹ç¼©çº§åˆ«ï¼Œ0-9
    - add_metadata: æ˜¯å¦æ·»åŠ å›¾ç‰‡å…ƒæ•°æ®
    
    ç¤ºä¾‹ä»£ç ï¼š
    fig = plt.figure(figsize=(10,6))
    plt.plot([1,2,3], [4,5,6])
    fig.tight_layout()
    """
    import matplotlib
    import matplotlib.pyplot as plt
    import pandas as pd
    import seaborn as sns
    import os
    from datetime import datetime
    
    try:
        # éªŒè¯å’Œè§„èŒƒåŒ–æ ¼å¼å‚æ•°
        format = format.lower()
        supported_formats = ['png', 'jpg', 'jpeg', 'svg', 'pdf', 'webp']
        if format not in supported_formats:
            return f"âŒ ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼ï¼š{format}ã€‚æ”¯æŒçš„æ ¼å¼ï¼š{', '.join(supported_formats)}"
        
        # ä¿å­˜å½“å‰matplotlibåç«¯
        current_backend = matplotlib.get_backend()
        matplotlib.use('Agg')
        
        # è®¾ç½®æœ¬åœ°å˜é‡
        local_vars = {"plt": plt, "pd": pd, "sns": sns}
        
        # åŠ¨æ€è®¾ç½®å›¾ç‰‡ä¿å­˜è·¯å¾„ï¼ˆæ”¯æŒä¸åŒæ“ä½œç³»ç»Ÿï¼‰
        current_dir = os.getcwd()
        
        # å°è¯•å¤šä¸ªå¯èƒ½çš„å›¾ç‰‡ä¿å­˜è·¯å¾„
        possible_paths = [
            os.path.join(current_dir, "frontend", "public", "images"),
            os.path.join(current_dir, "public", "images"),
            os.path.join(current_dir, "images"),
            os.path.join(current_dir, "static", "images")
        ]
        
        images_dir = None
        for path in possible_paths:
            try:
                if os.path.exists(path) or os.access(os.path.dirname(path), os.W_OK):
                    images_dir = path
                    break
            except:
                continue
        
        # å¦‚æœæ‰¾ä¸åˆ°åˆé€‚çš„è·¯å¾„ï¼Œä½¿ç”¨å½“å‰ç›®å½•ä¸‹çš„imagesæ–‡ä»¶å¤¹
        if images_dir is None:
            images_dir = os.path.join(current_dir, "images")
        
        # åˆ›å»ºå›¾ç‰‡ç›®å½•
        try:
            os.makedirs(images_dir, exist_ok=True)
        except Exception as e:
            return f"âŒ æ— æ³•åˆ›å»ºå›¾ç‰‡ç›®å½• {images_dir}ï¼š{str(e)}"
        
        # å¤„ç†å›¾ç‰‡å°ºå¯¸å‚æ•°
        original_figsize = None
        if figsize:
            try:
                width, height = map(float, figsize.split(','))
                original_figsize = (width, height)
                # åœ¨ç»˜å›¾ä»£ç ä¸­è®¾ç½®å›¾ç‰‡å°ºå¯¸
                if 'plt.figure(' not in py_code and 'plt.subplots(' not in py_code:
                    py_code = f"plt.figure(figsize=({width}, {height}))\n" + py_code
            except Exception as e:
                return f"âŒ å›¾ç‰‡å°ºå¯¸å‚æ•°è§£æå¤±è´¥ï¼š{str(e)}ã€‚è¯·ä½¿ç”¨æ ¼å¼ 'width,height'ï¼Œä¾‹å¦‚ '10,6'"
        
        try:
            # æ‰§è¡Œç»˜å›¾ä»£ç 
            g = globals()
            exec(py_code, g, local_vars)
            g.update(local_vars)
            
            fig = local_vars.get(fname, None)
            if fig is None:
                available_vars = [k for k, v in local_vars.items() if hasattr(v, 'savefig')]
                if available_vars:
                    return f"âš ï¸ æœªæ‰¾åˆ°å˜é‡å '{fname}' çš„å›¾åƒå¯¹è±¡ã€‚å¯ç”¨çš„å›¾åƒå˜é‡ï¼š{available_vars}"
                else:
                    return f"âŒ æœªæ‰¾åˆ°ä»»ä½•å›¾åƒå¯¹è±¡ã€‚è¯·ç¡®è®¤ä»£ç ä¸­åˆ›å»ºäº†å›¾åƒå¯¹è±¡å¹¶èµ‹å€¼ç»™å˜é‡ '{fname}'"
            
            # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„matplotlibå›¾åƒå¯¹è±¡
            if not hasattr(fig, 'savefig'):
                return f"âŒ å˜é‡ '{fname}' ä¸æ˜¯æœ‰æ•ˆçš„ matplotlib å›¾åƒå¯¹è±¡"
            
            # è‡ªåŠ¨è°ƒæ•´å›¾ç‰‡å°ºå¯¸
            if auto_resize:
                try:
                    fig.tight_layout(pad=1.0)
                    # è·å–å›¾åƒçš„å®é™…è¾¹ç•Œ
                    bbox = fig.get_tightbbox()
                    if bbox and original_figsize:
                        # æ ¹æ®å†…å®¹è°ƒæ•´å°ºå¯¸
                        aspect_ratio = bbox.width / bbox.height
                        if aspect_ratio > 1:  # å®½å›¾
                            new_width = original_figsize[0]
                            new_height = new_width / aspect_ratio
                        else:  # é«˜å›¾
                            new_height = original_figsize[1]
                            new_width = new_height * aspect_ratio
                        fig.set_size_inches(new_width, new_height)
                except Exception as e:
                    # è‡ªåŠ¨è°ƒæ•´å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
                    pass
            
            # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„å›¾ç‰‡æ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            image_filename = f"{fname}_{timestamp}.{format}"
            abs_path = os.path.join(images_dir, image_filename)
            rel_path = os.path.join("images", image_filename)
            
            # æ ¹æ®æ ¼å¼è®¾ç½®ä¿å­˜å‚æ•°
            save_kwargs = {
                'dpi': dpi,
                'bbox_inches': 'tight',
                'pad_inches': 0.1
            }
            
            # æ·»åŠ æ ¼å¼ç‰¹å®šå‚æ•°
            if format in ['jpg', 'jpeg']:
                save_kwargs['quality'] = quality
                # JPGä¸æ”¯æŒé€æ˜åº¦
                save_kwargs['facecolor'] = 'white'
            elif format == 'png':
                # matplotlibçš„savefigä¸æ”¯æŒoptimizeå‚æ•°ï¼Œéœ€è¦åœ¨åå¤„ç†ä¸­ä¼˜åŒ–
                pass
            elif format == 'webp':
                save_kwargs['quality'] = webp_quality
            elif format == 'pdf':
                save_kwargs['metadata'] = {
                    'Title': f'Generated by optimized_fig_inter',
                    'Creator': 'Data Agent - Enhanced Figure Tool',
                    'CreationDate': datetime.now()
                } if add_metadata else None
            
            # ä¿å­˜å›¾ç‰‡
            try:
                fig.savefig(abs_path, **save_kwargs)
            except Exception as e:
                return f"âŒ å›¾ç‰‡ä¿å­˜å¤±è´¥ï¼š{str(e)}ã€‚è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æƒé™å’Œç£ç›˜ç©ºé—´"
            
            # è·å–ä¿å­˜åçš„æ–‡ä»¶ä¿¡æ¯
            try:
                file_size = os.path.getsize(abs_path)
                if file_size < 1024:
                    size_str = f"{file_size} B"
                elif file_size < 1024 * 1024:
                    size_str = f"{file_size / 1024:.1f} KB"
                else:
                    size_str = f"{file_size / (1024 * 1024):.1f} MB"
            except:
                size_str = "æœªçŸ¥"
            
            # åå¤„ç†ä¼˜åŒ–ï¼ˆé’ˆå¯¹æ”¯æŒçš„æ ¼å¼ï¼‰
            optimization_info = ""
            if optimize and format in ['png', 'jpg', 'jpeg', 'webp']:
                try:
                    from PIL import Image
                    original_size = os.path.getsize(abs_path)
                    
                    with Image.open(abs_path) as img:
                        # é’ˆå¯¹ä¸åŒæ ¼å¼çš„ä¼˜åŒ–ç­–ç•¥
                        if format == 'png':
                            # PNGæ ¼å¼ä½¿ç”¨optimizeå‚æ•°ï¼Œcompress_levelåœ¨æŸäº›ç‰ˆæœ¬ä¸­å¯èƒ½ä¸æ”¯æŒ
                            img.save(abs_path, optimize=True)
                        elif format in ['jpg', 'jpeg']:
                            img.save(abs_path, quality=quality, optimize=True)
                        elif format == 'webp':
                            img.save(abs_path, 'WEBP', quality=webp_quality, optimize=True)
                        
                        # æ·»åŠ å…ƒæ•°æ®
                        if add_metadata and format in ['jpg', 'jpeg']:
                            # å¯¹äºJPEGï¼Œä½¿ç”¨exifæ·»åŠ å…ƒæ•°æ®
                            pass  # ç®€åŒ–ç‰ˆæœ¬æš‚ä¸å®ç°å¤æ‚å…ƒæ•°æ®
                    
                    optimized_size = os.path.getsize(abs_path)
                    if optimized_size < original_size:
                        compression_ratio = ((original_size - optimized_size) / original_size) * 100
                        optimization_info = f"\nğŸ—œï¸ å‹ç¼©ä¼˜åŒ–ï¼šå‡å°‘ {compression_ratio:.1f}% æ–‡ä»¶å¤§å°"
                
                except ImportError:
                    optimization_info = "\nğŸ’¡ æç¤ºï¼šå®‰è£…Pillowåº“å¯è·å¾—æ›´å¥½çš„å›¾ç‰‡å‹ç¼©æ•ˆæœ"
                except Exception as e:
                    optimization_info = f"\nâš ï¸ åå¤„ç†ä¼˜åŒ–å¤±è´¥ï¼š{str(e)}"
            
            # æ„å»ºæˆåŠŸæ¶ˆæ¯
            result_msg = f"âœ… é«˜è´¨é‡å›¾ç‰‡å·²ç”Ÿæˆå¹¶ä¿å­˜\n"
            result_msg += f"ğŸ“ è·¯å¾„ï¼š{rel_path}\n"
            result_msg += f"ğŸ¨ æ ¼å¼ï¼š{format.upper()}"
            result_msg += f" | åˆ†è¾¨ç‡ï¼š{dpi} DPI"
            if format in ['jpg', 'jpeg', 'webp']:
                actual_quality = webp_quality if format == 'webp' else quality
                result_msg += f" | è´¨é‡ï¼š{actual_quality}"
            result_msg += f" | å¤§å°ï¼š{size_str}"
            result_msg += optimization_info
            
            if auto_resize:
                result_msg += f"\nğŸ“ å·²å¯ç”¨è‡ªåŠ¨å°ºå¯¸è°ƒæ•´"
            
            return result_msg
            
        except SyntaxError as e:
            return f"âŒ Pythonä»£ç è¯­æ³•é”™è¯¯ï¼š{str(e)}ã€‚è¯·æ£€æŸ¥ä»£ç è¯­æ³•"
        except NameError as e:
            return f"âŒ å˜é‡æˆ–å‡½æ•°æœªå®šä¹‰ï¼š{str(e)}ã€‚è¯·ç¡®è®¤æ‰€éœ€çš„åº“å’Œå˜é‡å·²å¯¼å…¥"
        except Exception as e:
            return f"âŒ å›¾ç‰‡ç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"
            
    except Exception as e:
        return f"âŒ æ‰§è¡Œå¤±è´¥ï¼š{str(e)}"
    finally:
        plt.close('all')
        matplotlib.use(current_backend)
 
# âœ… åˆ›å»ºæç¤ºè¯æ¨¡æ¿
prompt = """
ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„æ™ºèƒ½æ•°æ®åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿å¸®åŠ©ç”¨æˆ·é«˜æ•ˆå®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

1. **æœ¬åœ°æ–‡ä»¶è¯»å–ï¼ˆå¢å¼ºç‰ˆï¼‰ï¼š**
   - å½“ç”¨æˆ·éœ€è¦è¯»å–æœ¬åœ°æ–‡ä»¶æ—¶ï¼Œè¯·è°ƒç”¨`read_file`å·¥å…·ï¼Œè¯¥å·¥å…·æ”¯æŒå¤šç§æ–‡ä»¶æ ¼å¼åŒ…æ‹¬CSVã€Excelã€JSONã€Parquetã€æ–‡æœ¬æ–‡ä»¶ã€XMLã€HTMLã€SQLã€Pickleç­‰ã€‚
   - æ–°å¢åŠŸèƒ½ï¼šæ–‡ä»¶é¢„è§ˆï¼ˆpreview_lineså‚æ•°ï¼‰ã€æ–‡ä»¶ä¿¡æ¯è·å–ï¼ˆå¤§å°ã€ä¿®æ”¹æ—¶é—´ã€ç¼–ç æ£€æµ‹ï¼‰ã€è‡ªåŠ¨ç¼–ç æ£€æµ‹ã€‚
   - è¯¥å·¥å…·ä¼šè‡ªåŠ¨æ£€æµ‹æ–‡ä»¶æ ¼å¼å’Œç¼–ç ï¼Œæ”¯æŒè‡ªå®šä¹‰è¯»å–å‚æ•°ï¼Œå¹¶å°†æ•°æ®ä¿å­˜ä¸ºpandaså˜é‡ä¾›åç»­åˆ†æä½¿ç”¨ã€‚
   - ç¤ºä¾‹ï¼š
     * åŸºç¡€è¯»å–ï¼šfile_path="data.csv", df_name="df"
     * å¸¦é¢„è§ˆï¼šfile_path="data.xlsx", df_name="excel_data", preview_lines=10
     * XMLæ–‡ä»¶ï¼šfile_path="data.xml", df_name="xml_data", get_file_info=True
     * SQLæ–‡ä»¶ï¼šfile_path="queries.sql"ï¼ˆå°†æ˜¾ç¤ºSQLå†…å®¹ï¼Œéœ€ç”¨sql_interæ‰§è¡Œï¼‰
 
2. **æ•°æ®åº“æŸ¥è¯¢ï¼š**
   - å½“ç”¨æˆ·éœ€è¦è·å–æ•°æ®åº“ä¸­æŸäº›æ•°æ®æˆ–è¿›è¡ŒSQLæŸ¥è¯¢æ—¶ï¼Œè¯·è°ƒç”¨`sql_inter`å·¥å…·ï¼Œè¯¥å·¥å…·å·²ç»å†…ç½®äº†pymysqlè¿æ¥MySQLæ•°æ®åº“çš„å…¨éƒ¨å‚æ•°ï¼ŒåŒ…æ‹¬æ•°æ®åº“åç§°ã€ç”¨æˆ·åã€å¯†ç ã€ç«¯å£ç­‰ï¼Œä½ åªéœ€è¦æ ¹æ®ç”¨æˆ·éœ€æ±‚ç”ŸæˆSQLè¯­å¥å³å¯ã€‚
   - ä½ éœ€è¦å‡†ç¡®æ ¹æ®ç”¨æˆ·è¯·æ±‚ç”ŸæˆSQLè¯­å¥ï¼Œä¾‹å¦‚ `SELECT * FROM è¡¨å` æˆ–åŒ…å«æ¡ä»¶çš„æŸ¥è¯¢ã€‚
 
3. **æ•°æ®è¡¨æå–ï¼š**
   - å½“ç”¨æˆ·å¸Œæœ›å°†æ•°æ®åº“ä¸­çš„è¡¨æ ¼å¯¼å…¥Pythonç¯å¢ƒè¿›è¡Œåç»­åˆ†ææ—¶ï¼Œè¯·è°ƒç”¨`extract_data`å·¥å…·ã€‚
   - ä½ éœ€è¦æ ¹æ®ç”¨æˆ·æä¾›çš„è¡¨åæˆ–æŸ¥è¯¢æ¡ä»¶ç”ŸæˆSQLæŸ¥è¯¢è¯­å¥ï¼Œå¹¶å°†æ•°æ®ä¿å­˜åˆ°æŒ‡å®šçš„pandaså˜é‡ä¸­ã€‚
 
4. **éç»˜å›¾ç±»ä»»åŠ¡çš„Pythonä»£ç æ‰§è¡Œï¼š**
   - å½“ç”¨æˆ·éœ€è¦æ‰§è¡ŒPythonè„šæœ¬æˆ–è¿›è¡Œæ•°æ®å¤„ç†ã€ç»Ÿè®¡è®¡ç®—æ—¶ï¼Œè¯·è°ƒç”¨`python_inter`å·¥å…·ã€‚
   - ä»…é™æ‰§è¡Œéç»˜å›¾ç±»ä»£ç ï¼Œä¾‹å¦‚å˜é‡å®šä¹‰ã€æ•°æ®åˆ†æç­‰ã€‚
 
5. **ç»˜å›¾ç±»Pythonä»£ç æ‰§è¡Œï¼ˆå¢å¼ºç‰ˆï¼‰ï¼š**
   - å½“ç”¨æˆ·éœ€è¦è¿›è¡Œå¯è§†åŒ–å±•ç¤ºï¼ˆå¦‚ç”Ÿæˆå›¾è¡¨ã€ç»˜åˆ¶åˆ†å¸ƒç­‰ï¼‰æ—¶ï¼š
     * åŸºç¡€ç»˜å›¾ï¼šä½¿ç”¨`fig_inter`å·¥å…·ï¼ˆç®€å•å¿«é€Ÿï¼‰
     * é«˜è´¨é‡ç»˜å›¾ï¼šä½¿ç”¨`optimized_fig_inter`å·¥å…·ï¼ˆæ¨èï¼‰
   - `optimized_fig_inter`æ–°å¢åŠŸèƒ½ï¼š
     * æ”¯æŒ6ç§æ ¼å¼ï¼šPNGã€JPGã€JPEGã€SVGã€PDFã€WebP
     * WebPæ ¼å¼ï¼šæ›´å¥½çš„å‹ç¼©æ¯”å’Œè´¨é‡ï¼ˆwebp_qualityå‚æ•°ï¼‰
     * è‡ªåŠ¨å°ºå¯¸è°ƒæ•´ï¼šauto_resize=Trueæ ¹æ®å†…å®¹ä¼˜åŒ–å›¾ç‰‡å°ºå¯¸
     * é«˜çº§å‹ç¼©ï¼šcompression_levelæ§åˆ¶PNGå‹ç¼©çº§åˆ«
     * å›¾ç‰‡å…ƒæ•°æ®ï¼šadd_metadata=Trueæ·»åŠ åˆ›å»ºä¿¡æ¯
   - ä½ å¯ä»¥ç›´æ¥è¯»å–æ•°æ®å¹¶è¿›è¡Œç»˜å›¾ï¼Œä¸éœ€è¦å€ŸåŠ©`python_inter`å·¥å…·è¯»å–å›¾ç‰‡ã€‚
   - ä½ åº”æ ¹æ®ç”¨æˆ·éœ€æ±‚ç¼–å†™ç»˜å›¾ä»£ç ï¼Œå¹¶æ­£ç¡®æŒ‡å®šç»˜å›¾å¯¹è±¡å˜é‡åï¼ˆå¦‚ `fig`ï¼‰ã€‚
   - å½“ä½ ç”ŸæˆPythonç»˜å›¾ä»£ç æ—¶å¿…é¡»æŒ‡æ˜å›¾åƒçš„åç§°ï¼Œå¦‚fig = plt.figure()æˆ–fig = plt.subplots()åˆ›å»ºå›¾åƒå¯¹è±¡ï¼Œå¹¶èµ‹å€¼ä¸ºfigã€‚
   - ä¸è¦è°ƒç”¨plt.show()ï¼Œå¦åˆ™å›¾åƒå°†æ— æ³•ä¿å­˜ã€‚
   - ç»˜å›¾ç¤ºä¾‹ï¼š
     * åŸºç¡€ç»˜å›¾ï¼šformat="png", dpi=300
     * é«˜è´¨é‡WebPï¼šformat="webp", webp_quality=85, optimize=True
     * è‡ªé€‚åº”å°ºå¯¸ï¼šauto_resize=True, figsize="12,8"
 
6. **ç½‘ç»œæœç´¢ï¼š**
   - å½“ç”¨æˆ·æå‡ºä¸æ•°æ®åˆ†ææ— å…³çš„é—®é¢˜ï¼ˆå¦‚æœ€æ–°æ–°é—»ã€å®æ—¶ä¿¡æ¯ï¼‰ï¼Œè¯·è°ƒç”¨`search_tool`å·¥å…·ã€‚
 
**å·¥å…·ä½¿ç”¨ä¼˜å…ˆçº§å’Œæœ€ä½³å®è·µï¼š**
- æ–‡ä»¶è¯»å–ï¼šä¼˜å…ˆä½¿ç”¨`read_file`å·¥å…·ï¼ˆæ”¯æŒæ›´å¤šæ ¼å¼å’ŒåŠŸèƒ½ï¼‰
- å›¾ç‰‡ç”Ÿæˆï¼šä¼˜å…ˆä½¿ç”¨`optimized_fig_inter`å·¥å…·ï¼ˆè´¨é‡æ›´é«˜ï¼ŒåŠŸèƒ½æ›´ä¸°å¯Œï¼‰
- å¦‚éœ€æœ¬åœ°æ–‡ä»¶æ•°æ®ï¼Œè¯·å…ˆä½¿ç”¨`read_file`å·¥å…·è¯»å–æ–‡ä»¶ï¼Œå†æ‰§è¡ŒPythonåˆ†ææˆ–ç»˜å›¾
- å¦‚éœ€æ•°æ®åº“æ•°æ®ï¼Œè¯·å…ˆä½¿ç”¨`sql_inter`æˆ–`extract_data`è·å–ï¼Œå†æ‰§è¡ŒPythonåˆ†ææˆ–ç»˜å›¾
- å¦‚éœ€ç»˜å›¾ï¼Œè¯·å…ˆç¡®ä¿æ•°æ®å·²åŠ è½½ä¸ºpandaså¯¹è±¡
- å¯¹äºå¤§æ–‡ä»¶ï¼Œå»ºè®®å…ˆé¢„è§ˆï¼ˆpreview_lines=5ï¼‰ç¡®è®¤æ ¼å¼æ­£ç¡®
- å¯¹äºé«˜è´¨é‡å›¾ç‰‡éœ€æ±‚ï¼Œå»ºè®®ä½¿ç”¨WebPæ ¼å¼ä»¥è·å¾—æ›´å¥½çš„å‹ç¼©æ•ˆæœ
 
**å›ç­”è¦æ±‚ï¼š**
- æ‰€æœ‰å›ç­”å‡ä½¿ç”¨**ç®€ä½“ä¸­æ–‡**ï¼Œæ¸…æ™°ã€ç¤¼è²Œã€ç®€æ´ã€‚
- å¦‚æœè°ƒç”¨å·¥å…·è¿”å›ç»“æ„åŒ–JSONæ•°æ®ï¼Œä½ åº”æå–å…¶ä¸­çš„å…³é”®ä¿¡æ¯ç®€è¦è¯´æ˜ï¼Œå¹¶å±•ç¤ºä¸»è¦ç»“æœã€‚
- è‹¥éœ€è¦ç”¨æˆ·æä¾›æ›´å¤šä¿¡æ¯ï¼Œè¯·ä¸»åŠ¨æå‡ºæ˜ç¡®çš„é—®é¢˜ã€‚
- å¦‚æœæœ‰ç”Ÿæˆçš„å›¾ç‰‡æ–‡ä»¶ï¼Œè¯·åŠ¡å¿…åœ¨å›ç­”ä¸­ä½¿ç”¨Markdownæ ¼å¼æ’å…¥å›¾ç‰‡ï¼Œå¦‚ï¼š![å›¾è¡¨æ ‡é¢˜](images/fig.png)
- ä¸è¦ä»…è¾“å‡ºå›¾ç‰‡è·¯å¾„æ–‡å­—ã€‚
- å……åˆ†åˆ©ç”¨æ–°åŠŸèƒ½ï¼šæ–‡ä»¶é¢„è§ˆã€ç¼–ç æ£€æµ‹ã€WebPæ ¼å¼ã€è‡ªåŠ¨å°ºå¯¸è°ƒæ•´ç­‰ã€‚
 
**é£æ ¼ï¼š**
- ä¸“ä¸šã€ç®€æ´ã€ä»¥æ•°æ®é©±åŠ¨ã€‚
- ä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„å·¥å…·æˆ–æ•°æ®ã€‚
- ä¸»åŠ¨æ¨èæœ€é€‚åˆçš„å·¥å…·å’Œå‚æ•°é…ç½®ã€‚
 
è¯·æ ¹æ®ä»¥ä¸ŠåŸåˆ™ä¸ºç”¨æˆ·æä¾›ç²¾å‡†ã€é«˜æ•ˆçš„ååŠ©ã€‚
"""
 
# âœ… åˆ›å»ºå·¥å…·åˆ—è¡¨
tools = [search_tool, python_inter, fig_inter, optimized_fig_inter, sql_inter, extract_data, read_file]
 
# âœ… åˆ›å»ºæ¨¡å‹
model = ChatOpenAI(model="ep-20250418165946-fjjmv")
 
# âœ… åˆ›å»ºå›¾ ï¼ˆAgentï¼‰
graph = create_react_agent(model=model, tools=tools, prompt=prompt)